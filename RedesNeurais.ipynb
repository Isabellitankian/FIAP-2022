{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RedesNeurais",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMKh3VMbhxdYaA6dKQCF1/H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Isabellitankian/FIAP-2022/blob/main/RedesNeurais.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usando 2 redes de treianmentos para prever os valores, depois da avaliação do Dataframe"
      ],
      "metadata": {
        "id": "n89aPC0fVjnZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1º Passo importar as bibliotecas."
      ],
      "metadata": {
        "id": "C8kF4mlKzAcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd #pandas faz tudo e mais um pouco.\n",
        "import matplotlib.pyplot as plt #para construir e customizar gráficos.\n",
        "import seaborn as sns #para visualizar uns gráficos.\n",
        "import numpy as np #numpy porque é sempre bom importar numpy né. \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.neural_network import MLPRegressor"
      ],
      "metadata": {
        "id": "lqXYgNeby-qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2º Começar com a análise dos dados e ordenação."
      ],
      "metadata": {
        "id": "ECbdwYq91TyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imoveis = pd.read_csv('https://tinyurl.com/alugueis-sp-df') #Definindo que o arquivo ficará com o nome \"imoveis\"\n",
        "imoveis.sort_values('Price', ascending=True, inplace=True) #Colocando os valores em ordem crescente\n",
        "imoveis = imoveis[imoveis['Negotiation Type'] == 'sale'] #Filtrando por \"SALE\" apenas\n",
        "imoveis.head(20)"
      ],
      "metadata": {
        "id": "p7dCtKmvxzoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Excluindo as colunas\n",
        "imoveis = imoveis.drop('Longitude',axis=1) \n",
        "imoveis = imoveis.drop('Latitude',axis=1)\n",
        "imoveis = imoveis.drop('New',axis=1)\n",
        "imoveis = imoveis.drop('District',axis=1)\n",
        "imoveis = imoveis.drop('Negotiation Type',axis=1)\n",
        "imoveis = imoveis.drop('Property Type',axis=1)"
      ],
      "metadata": {
        "id": "2xqGESwa479v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imoveis.info() #Para obter informações dataframe"
      ],
      "metadata": {
        "id": "nrptNOtgz7y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imoveis.describe() #Para ver uma descrição mais detalhada "
      ],
      "metadata": {
        "id": "uHXTjp751Fxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3º Começar com a limpeza dos dados."
      ],
      "metadata": {
        "id": "rycykp781g_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imoveis.drop_duplicates(keep='first', inplace=True) #Remover a duplicidade dos dados.\n",
        "imoveis.head(10)"
      ],
      "metadata": {
        "id": "jxoDY52b1kbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imoveis = imoveis.corr()\n",
        "plt.figure(figsize=(16, 6))\n",
        "heatmap = sns.heatmap(imoveis, vmin=-1, vmax=1, annot=True)\n",
        "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12)"
      ],
      "metadata": {
        "id": "W1VYUxFyg5hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotando o gráfico\n",
        "plt.scatter(imoveis[\"Price\"], imoveis[\"Size\"])\n",
        "plt.xlabel(\"Tamanho\")\n",
        "plt.ylabel(\"Valor\")\n",
        "plt.title(\"Relação entre tamanho do apartamento e o valor.\")"
      ],
      "metadata": {
        "id": "nX5TG5OWaOrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pré - processamento"
      ],
      "metadata": {
        "id": "PwNDwLL5gRgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = imoveis.drop(columns=['Price'])\n",
        "Y = imoveis[\"Price\"]"
      ],
      "metadata": {
        "id": "CCYbyGJTgPm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dividir em conjuntos de treinamento e teste\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)"
      ],
      "metadata": {
        "id": "AOuksSfTnOeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalização \n",
        "escala = StandardScaler()\n",
        "escala.fit(X)\n",
        "X_train_norm = escala.transform(X)\n"
      ],
      "metadata": {
        "id": "LwXEf0hFmLQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Processamento"
      ],
      "metadata": {
        "id": "sCSQPAbSn7kw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#MLP Regressor \n",
        "rna = MLPRegressor(hidden_layer_sizes=(20, 15, 7),  #Numero de camadas ocultas da minha rede\n",
        "                   max_iter=5000,                     #Numero máximo de iterações \n",
        "                   tol=0.000001,                       #taxa de tolerancia, minima\n",
        "                   learning_rate_init=0.1,          #taxa de aprendizado de 0.1\n",
        "                   solver='sgd',                     #estratégia é o algoritmo de decida do gradiente \"estoquetico\" kkkk\n",
        "                   activation='logistic',              #função \n",
        "                   learning_rate='constant',               #taxa constante \n",
        "                   verbose=2,          #visualizar cada época\n",
        "                   )     \n"
      ],
      "metadata": {
        "id": "CrkTBBwTn4ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rna.fit(X_train_norm, Y)"
      ],
      "metadata": {
        "id": "4O85PQFXqHzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SGRD Regressor \n",
        "reglinear = SGDRegressor(max_iter=5000,\n",
        "                         tol=0.000001,\n",
        "                         eta0=0.1,\n",
        "                         learning_rate='constant',               #taxa constante \n",
        "                   verbose=2, \n",
        ")"
      ],
      "metadata": {
        "id": "RIVobUf_qWos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reglinear.fit(X_train_norm, Y)"
      ],
      "metadata": {
        "id": "J96H1mGjqpU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pós - processamento"
      ],
      "metadata": {
        "id": "ZPiOJDz7rQxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Previsão no conjunto de tese\n",
        "Y_rna_previsao = rna.predict(X_train_norm)\n",
        "Y_r1_previsao = reglinear.predict(X_train_norm)\n",
        "print(Y_rna_previsao,Y_r1_previsao)"
      ],
      "metadata": {
        "id": "vtgTV3VErP5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calcular o R*2\n",
        "r2_rna = r2_score(Y, Y_rna_previsao)\n",
        "r2_r1 = r2_score(Y, Y_r1_previsao)\n"
      ],
      "metadata": {
        "id": "UKgBAqimroCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pritando o resultado \n",
        "print(\"R2 RNA:\", r2_rna)\n",
        "print(\"R2 RL:\", r2_r1)"
      ],
      "metadata": {
        "id": "RWAEmRnlsHyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(X_train_norm)"
      ],
      "metadata": {
        "id": "2DFv4KM5TLS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importando meu Dataset com os Ap que eu peguei no site do VivaReal\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "xxakbYyqmK5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Atribuindo meu Dataset a variável Ap\n",
        "ap = pd.read_excel(\"apartamentosGiovanniGronchi.xlsx\") "
      ],
      "metadata": {
        "id": "bmXXiUw8mpq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Excluindo as colunas, assim como eu fiz la em cima\n",
        "ap = ap.drop('Longitude', axis=1) \n",
        "ap = ap.drop('Latitude', axis=1)\n",
        "ap = ap.drop('New', axis=1)\n",
        "ap = ap.drop('District', axis=1)\n",
        "ap = ap.drop('Negotiation Type', axis=1)\n",
        "ap = ap.drop('Property Type', axis=1)\n",
        "ap = ap.drop('Elevator', axis=1)\n"
      ],
      "metadata": {
        "id": "P47Okgccoia5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Usando o Predict para prever, mas agora com o meu dataframe \n",
        "Y_reglinear_prev_futuro_ap = reglinear.predict(ap)\n",
        "print(\"Previsão\", Y_reglinear_prev_futuro_ap)"
      ],
      "metadata": {
        "id": "uisv8-JVdj9l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}